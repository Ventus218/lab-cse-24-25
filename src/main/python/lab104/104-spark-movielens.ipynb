{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99b6b25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T15:34:09.444324Z",
     "iopub.status.busy": "2022-02-28T15:34:09.441785Z",
     "iopub.status.idle": "2022-02-28T15:34:10.302913Z",
     "shell.execute_reply": "2022-02-28T15:34:10.302209Z",
     "shell.execute_reply.started": "2022-02-28T15:34:09.444282Z"
    }
   },
   "source": [
    "# 104 Spark - Movielens\n",
    "\n",
    "The goal of this lab is to run some analysis on a different dataset, [MovieLens](https://grouplens.org/datasets/movielens/), on AWS.\n",
    "\n",
    "- [Spark programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "- [RDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/RDD.html)\n",
    "- [PairRDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)\n",
    "\n",
    "**Download the dataset** from [here](https://big.csr.unibo.it/downloads/bigdata/ml-dataset.zip), unzip it and put it in the ```datasets/big``` folder.\n",
    "\n",
    "- ml-movies.csv (<u>movieId</u>:Long, title:String, genres:String) \n",
    "    - genres are separated by pipelines  (e.g., \"comedy|drama|action\")\n",
    "    - each movie is associated with many ratings\n",
    "\n",
    "- ml-ratings.csv (<u>userId</u>:Long, <u>movieId</u>:Long, rating:Double, year:Int)\n",
    "    - each rating is associated with many tags\n",
    "    - ml-ratings-sample.csv is a small sample of ml-ratings.csv, useful for developing\n",
    "- ml-tags.csv (<u>userId</u>:Long, <u>movieId</u>:Long, <u>tag</u>:String, year:Int) "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T08:58:49.670499Z",
     "start_time": "2024-11-13T08:58:42.406878Z"
    }
   },
   "cell_type": "code",
   "source": "import org.apache.spark",
   "id": "c2b673a91143a3bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://lab42-04-01.campusfc.dir.unibo.it:4040\n",
       "SparkContext available as 'sc' (version = 3.5.2, master = local[*], app id = local-1731488324655)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "6297e3f5-17d3-44ba-a06c-8b1acf0ca078",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-13T08:58:53.604123Z",
     "start_time": "2024-11-13T08:58:53.356032Z"
    }
   },
   "source": [
    "val path_to_datasets = \"../../../../datasets/big/\"\n",
    "\n",
    "val path_ml_movies = path_to_datasets + \"ml-movies.csv\"\n",
    "val path_ml_ratings = path_to_datasets + \"ml-ratings-sample.csv\"\n",
    "val path_ml_tags = path_to_datasets + \"ml-tags.csv\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_to_datasets: String = ../../../../datasets/big/\r\n",
       "path_ml_movies: String = ../../../../datasets/big/ml-movies.csv\r\n",
       "path_ml_ratings: String = ../../../../datasets/big/ml-ratings-sample.csv\r\n",
       "path_ml_tags: String = ../../../../datasets/big/ml-tags.csv\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e643e27d-b710-43cb-bc3d-7bca65e93b15",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-13T08:59:33.104362Z",
     "start_time": "2024-11-13T08:59:32.533152Z"
    }
   },
   "source": [
    "import java.util.Calendar\n",
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.HashPartitioner\n",
    "\n",
    "object MovieLensParser {\n",
    "\n",
    "  val noGenresListed = \"(no genres listed)\"\n",
    "  val commaRegex = \",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "  val pipeRegex = \"\\\\|(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"\n",
    "  val quotes = \"\\\"\"\n",
    "  \n",
    "  /** Convert from timestamp (String) to year (Int) */\n",
    "  def yearFromTimestamp(timestamp: String): Int = {\n",
    "    val cal = Calendar.getInstance()\n",
    "    cal.setTimeInMillis(timestamp.trim.toLong * 1000L)\n",
    "    cal.get(Calendar.YEAR)\n",
    "  }\n",
    "\n",
    "  /** Function to parse movie records\n",
    "   *\n",
    "   *  @param line line that has to be parsed\n",
    "   *  @return tuple containing movieId, title and genres, none in case of input errors\n",
    "   */\n",
    "  def parseMovieLine(line: String): Option[(Long, String, String)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      var title = input(1).trim\n",
    "      title = if(title.startsWith(quotes)) title.substring(1) else title\n",
    "      title = if(title.endsWith(quotes)) title.substring(0, title.length - 1) else title\n",
    "      Some(input(0).trim.toLong, title, input(2).trim)\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /** Function to parse rating records\n",
    "   *\n",
    "   *  @param line line that has to be parsed\n",
    "   *  @return tuple containing userId, movieId, rating, and year none in case of input errors\n",
    "   */\n",
    "  def parseRatingLine(line: String): Option[(Long, Long, Double, Int)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      Some(input(0).trim.toLong, input(1).trim.toLong, input(2).trim.toDouble, yearFromTimestamp(input(3)))\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /** Function to parse tag records\n",
    "   *\n",
    "   *  @param line line that has to be parsed\n",
    "   *  @return tuple containing userId, movieId, tag, and year, none in case of input errors\n",
    "   */\n",
    "  def parseTagLine(line: String) : Option[(Long, Long, String, Int)] = {\n",
    "    try {\n",
    "      val input = line.split(commaRegex)\n",
    "      Some(input(0).trim.toLong, input(1).trim.toLong, input(2), yearFromTimestamp(input(3)))\n",
    "    } catch {\n",
    "      case _: Exception => None\n",
    "    }\n",
    "  }\n",
    "\n",
    "}"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import java.util.Calendar\r\n",
       "import org.apache.spark.sql.SaveMode\r\n",
       "import org.apache.spark.HashPartitioner\r\n",
       "defined object MovieLensParser\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "3e69ae6f-50f6-4e2f-9fe8-ff6d747e675f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-13T08:59:37.701868Z",
     "start_time": "2024-11-13T08:59:36.601660Z"
    }
   },
   "source": [
    "val rddMovies = sc.textFile(path_ml_movies).flatMap(MovieLensParser.parseMovieLine)\n",
    "val rddRatings = sc.textFile(path_ml_ratings).flatMap(MovieLensParser.parseRatingLine)\n",
    "val rddTags = sc.textFile(path_ml_tags).flatMap(MovieLensParser.parseTagLine)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMovies: org.apache.spark.rdd.RDD[(Long, String, String)] = MapPartitionsRDD[2] at flatMap at <console>:32\r\n",
       "rddRatings: org.apache.spark.rdd.RDD[(Long, Long, Double, Int)] = MapPartitionsRDD[5] at flatMap at <console>:33\r\n",
       "rddTags: org.apache.spark.rdd.RDD[(Long, Long, String, Int)] = MapPartitionsRDD[8] at flatMap at <console>:34\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "d9dfbdfd-2ee7-4488-a95f-9f1f809e581c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T15:59:00.715374Z",
     "iopub.status.busy": "2022-02-28T15:59:00.715148Z",
     "iopub.status.idle": "2022-02-28T15:59:01.005430Z",
     "shell.execute_reply": "2022-02-28T15:59:01.004685Z",
     "shell.execute_reply.started": "2022-02-28T15:59:00.715351Z"
    },
    "tags": []
   },
   "source": [
    "## 104-1 Datasets exploration\n",
    "\n",
    "Cache the datasets and answer the following questions:\n",
    "\n",
    "- How many (distinct) users, movies, ratings, and tags?\n",
    "- How many (distinct) genres?\n",
    "- On average, how many ratings per user?\n",
    "- On average, how many ratings per movie?\n",
    "- On average, how many genres per movie?\n",
    "- What is the range of ratings?\n",
    "- Which years? (print an ordered list)\n",
    "- On average, how many ratings per year?\n",
    "\n",
    "Try these locally as \"extra\" exercises; solutions will be published later on."
   ]
  },
  {
   "cell_type": "code",
   "id": "1f07a5b9-baaf-4564-8988-33e23ced42ea",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-13T09:02:52.393910Z",
     "start_time": "2024-11-13T09:02:52.176986Z"
    }
   },
   "source": [
    "val rddMoviesCached = rddMovies.cache()\n",
    "val rddRatingsCached = rddRatings.cache()\n",
    "val rddTagsCached = rddTags.cache()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMoviesCached: rddMovies.type = MapPartitionsRDD[2] at flatMap at <console>:32\r\n",
       "rddRatingsCached: rddRatings.type = MapPartitionsRDD[5] at flatMap at <console>:33\r\n",
       "rddTagsCached: rddTags.type = MapPartitionsRDD[8] at flatMap at <console>:34\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "9a4016ac-cb34-48d0-a45c-29122e5fa59a",
   "metadata": {},
   "source": [
    "## 104-2 Compute the average rating for each movie\n",
    "\n",
    "- Export the result to a file\n",
    "- Do not start from cached RDDs\n",
    "- Evaluate:\n",
    "  - Join-and-Aggregate\n",
    "  - Aggregate-and-Join\n",
    "  - Aggregate-and-BroadcastJoin"
   ]
  },
  {
   "cell_type": "code",
   "id": "feb49547-58f9-4994-929a-da867e2e4cc6",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-13T09:04:08.014719Z",
     "start_time": "2024-11-13T09:04:07.707620Z"
    }
   },
   "source": [
    "val path_output_avgRatPerMovie = \"../../../../output/avgRatPerMovie\"\n",
    "// rdd.coalesce(1).toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie)\n",
    "\n",
    "sc.getPersistentRDDs.foreach(_._2.unpersist())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_output_avgRatPerMovie: String = ../../../../output/avgRatPerMovie\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "dd4fdb9c-7a73-43a0-a121-fe98dc71ea02",
   "metadata": {},
   "source": "### Join-and-Aggregate"
  },
  {
   "cell_type": "code",
   "id": "35060678-a714-4871-a0ee-bd6d1149c2c9",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-13T09:05:15.474120Z",
     "start_time": "2024-11-13T09:05:10.875663Z"
    }
   },
   "source": [
    "val rddMoviesKV = rddMovies.map(x => (x._1,x._2))\n",
    "val avgRatPerMovie = rddRatings.\n",
    "    map(x => ((x._2),(x._3))).\n",
    "    join(rddMoviesKV).\n",
    "    map({case (m,(r,t)) => ((m,t),r)}).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "    map({case ((m,t),(sum,cnt)) => (m, t, sum/cnt, cnt)}).\n",
    "    coalesce(1).\n",
    "    toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMoviesKV: org.apache.spark.rdd.RDD[(Long, String)] = MapPartitionsRDD[21] at map at <console>:31\r\n",
       "avgRatPerMovie: Unit = ()\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Aggregate-and-Join",
   "id": "f30a78f233f9cdaf"
  },
  {
   "cell_type": "code",
   "id": "45bddac2-b5b0-4eee-b34d-312877a7262e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:05:47.695139Z",
     "start_time": "2024-11-13T09:05:43.950378Z"
    }
   },
   "source": [
    "val rddMoviesKV = rddMovies.map(x => (x._1,x._2))\n",
    "val avgRatPerMovie = rddRatings.\n",
    "    map(x => (x._2,x._3)).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "    mapValues({case (sum,cnt) => (sum/cnt, cnt)}).\n",
    "    join(rddMoviesKV).\n",
    "    map({case (m,((r,cnt),t)) => (m,t,r,cnt)}).\n",
    "    coalesce(1).\n",
    "    toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie)\n",
    "\n",
    "//avgRatPerMovie.toDebugString"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMoviesKV: org.apache.spark.rdd.RDD[(Long, String)] = MapPartitionsRDD[33] at map at <console>:31\r\n",
       "avgRatPerMovie: Unit = ()\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "887bbb2f-5b97-4918-ae8c-dd98f252a6e6",
   "metadata": {},
   "source": "### Aggregate-and-BroadcastJoin"
  },
  {
   "cell_type": "code",
   "id": "d17c7e50-802a-46e7-b522-2269e23c0085",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-13T09:05:59.847444Z",
     "start_time": "2024-11-13T09:05:56.007269Z"
    }
   },
   "source": [
    "val rddMoviesKV = rddMovies.map(x => (x._1,x._2))\n",
    "val bRddMovies = sc.broadcast(rddMoviesKV.collectAsMap())\n",
    "val avgRatPerMovie = rddRatings.\n",
    "    map(x => ((x._2),(x._3))).\n",
    "    aggregateByKey((0.0,0.0))((a,v)=>(a._1+v, a._2+1),(a1,a2)=>(a1._1+a2._1,a1._2+a2._2)).\n",
    "    mapValues({case (sum,cnt) => (sum/cnt, cnt)}).\n",
    "    map({case (m,(r,cnt)) => (m,bRddMovies.value.get(m),r,cnt)}).\n",
    "    coalesce(1).\n",
    "    toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(path_output_avgRatPerMovie)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddMoviesKV: org.apache.spark.rdd.RDD[(Long, String)] = MapPartitionsRDD[45] at map at <console>:32\r\n",
       "bRddMovies: org.apache.spark.broadcast.Broadcast[scala.collection.Map[Long,String]] = Broadcast(15)\r\n",
       "avgRatPerMovie: Unit = ()\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "c07050d2-4447-4765-814d-2cd0ff1402c1",
   "metadata": {},
   "source": [
    "## 104-3 Compute the average rating for each genre\n",
    "\n",
    "Two possible workflows:\n",
    "\n",
    "1. Pre-aggregation (3 shuffles)\n",
    "\n",
    "  - Aggregate ratings by movieId\n",
    "  - Join with movies and map to genres\n",
    "  - Aggregate by genres\n",
    "  \n",
    "2. Join & aggregate (2 shuffles)\n",
    "\n",
    "  - Join with movies and map to genres\n",
    "  - Aggregate by genres"
   ]
  },
  {
   "cell_type": "code",
   "id": "191a8f82-2006-49a6-9a99-9de6638df74a",
   "metadata": {
    "tags": []
   },
   "source": [
    "val path_output_avgRatPerGenre = \"s3a://\"+bucketname+\"/spark/avgRatPerGenre\"\n",
    "\n",
    "for ((k,v) <- sc.getPersistentRDDs) {\n",
    "  v.unpersist()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
